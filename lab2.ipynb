{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa92167",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35a995ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d004da",
   "metadata": {},
   "source": [
    "Загрузка датасета классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f49f35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart = pd.read_csv('heart.csv')\n",
    "X_cls = df_heart.drop('target', axis=1)\n",
    "y_cls = df_heart['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3531f",
   "metadata": {},
   "source": [
    "Разделение на тестовые и тренировочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4302d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf532d6b",
   "metadata": {},
   "source": [
    "Загрузка датасета регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d689f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy = pd.read_csv('energy_efficiency_data.csv')\n",
    "X_reg = df_energy.drop(['Heating_Load', 'Cooling_Load'], axis=1)\n",
    "y_reg = df_energy['Heating_Load']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052917cb",
   "metadata": {},
   "source": [
    "Определение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69fd51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area', 'Overall_Height']\n",
    "cat_features = ['Orientation', 'Glazing_Area', 'Glazing_Area_Distribution']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c533b",
   "metadata": {},
   "source": [
    "Разделение на тестовые и тренировочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "646025b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a7f34",
   "metadata": {},
   "source": [
    "Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8cada093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegressor:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        y = np.asarray(y, dtype=np.float64)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            y_pred = X @ self.weights + self.bias\n",
    "            dw = (1 / n_samples) * X.T @ (y_pred - y)\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        return X @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439b4a4",
   "metadata": {},
   "source": [
    "Логическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "feba0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticClassifier:\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iterations\n",
    "        self.W = None\n",
    "        self.classes_ = None\n",
    "        self.label_to_index = None\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        z_stable = z - np.max(z, axis=1, keepdims=True)\n",
    "        exp_z = np.exp(z_stable)\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        y = np.asarray(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        self.label_to_index = {label: i for i, label in enumerate(self.classes_)}\n",
    "\n",
    "        y_onehot = np.zeros((n_samples, n_classes))\n",
    "        for i, label in enumerate(y):\n",
    "            y_onehot[i, self.label_to_index[label]] = 1\n",
    "\n",
    "        Xb = np.hstack([np.ones((n_samples, 1)), X])\n",
    "        self.W = np.zeros((n_features + 1, n_classes))\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            logits = Xb @ self.W\n",
    "            probs = self._softmax(logits)\n",
    "            grad = (1 / n_samples) * Xb.T @ (probs - y_onehot)\n",
    "            self.W -= self.lr * grad\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        Xb = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        logits = Xb @ self.W\n",
    "        return self._softmax(logits)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        class_indices = np.argmax(probs, axis=1)\n",
    "        return self.classes_[class_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c650c76",
   "metadata": {},
   "source": [
    "Метрики для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7982307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee2f03",
   "metadata": {},
   "source": [
    "Метрики для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "afaaa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98bc21",
   "metadata": {},
   "source": [
    "Запуск базовой модели логической регрессии sklearn (классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02969aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_log_base = LogisticRegression(max_iter=10000, random_state=42)\n",
    "sk_log_base.fit(X_train_cls, y_train_cls)\n",
    "y_pred_sk_log = sk_log_base.predict(X_test_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff5e96",
   "metadata": {},
   "source": [
    "Запуск базовой кастомной модели логической регрессии (классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d37f9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_log_base = MyLogisticClassifier(learning_rate=0.1, n_iterations=2000)\n",
    "my_log_base.fit(X_train_cls.values, y_train_cls.values)\n",
    "y_pred_my_log = my_log_base.predict(X_test_cls.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b7dbc",
   "metadata": {},
   "source": [
    "Вывод метрик классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a800548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: {'Accuracy': 0.8146341463414634, 'F1': 0.811967851371656, 'ROC-AUC': 0.8119047619047619}\n",
      "Custom : {'Accuracy': 0.624390243902439, 'F1': 0.5806587275712194, 'ROC-AUC': 0.6323809523809523}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn:\", evaluate_classification(y_test_cls, y_pred_sk_log))\n",
    "print(\"Custom :\", evaluate_classification(y_test_cls, y_pred_my_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7b966",
   "metadata": {},
   "source": [
    "Запуск базовой модели линейной регрессии sklearn (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08b51263",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lin_base = LinearRegression()\n",
    "sk_lin_base.fit(X_train_reg, y_train_reg)\n",
    "y_pred_sk_lin = sk_lin_base.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e363ef",
   "metadata": {},
   "source": [
    "Запуск кастомной базовой модели линейной регрессии (регрессия) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3f79fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Алексей\\AppData\\Local\\Temp\\ipykernel_3192\\3091210259.py:18: RuntimeWarning: overflow encountered in matmul\n",
      "  dw = (1 / n_samples) * X.T @ (y_pred - y)\n",
      "c:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\Алексей\\AppData\\Local\\Temp\\ipykernel_3192\\3091210259.py:18: RuntimeWarning: invalid value encountered in matmul\n",
      "  dw = (1 / n_samples) * X.T @ (y_pred - y)\n",
      "C:\\Users\\Алексей\\AppData\\Local\\Temp\\ipykernel_3192\\3091210259.py:20: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.weights -= self.lr * dw\n",
      "C:\\Users\\Алексей\\AppData\\Local\\Temp\\ipykernel_3192\\3091210259.py:21: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  self.bias -= self.lr * db\n"
     ]
    }
   ],
   "source": [
    "my_lin_base = MyLinearRegressor(learning_rate=0.001, n_iterations=2000)\n",
    "my_lin_base.fit(X_train_reg.values, y_train_reg.values)\n",
    "y_pred_my_lin = my_lin_base.predict(X_test_reg.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d083d",
   "metadata": {},
   "source": [
    "Вывод метрик регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a709f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: {'MAE': 2.1820470221279193, 'RMSE': np.float64(3.0254235827736173), 'R2': 0.912184095154691}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSklearn:\u001b[39m\u001b[33m\"\u001b[39m, evaluate_regression(y_test_reg, y_pred_sk_lin))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCustom :\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mevaluate_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_my_lin\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mevaluate_regression\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_regression\u001b[39m(y_true, y_pred):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m      4\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m'\u001b[39m: np.sqrt(mean_squared_error(y_true, y_pred)),\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mR2\u001b[39m\u001b[33m'\u001b[39m: r2_score(y_true, y_pred)\n\u001b[32m      6\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:284\u001b[39m, in \u001b[36mmean_absolute_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[32m    229\u001b[39m \n\u001b[32m    230\u001b[39m \u001b[33;03mThe mean absolute error is a non-negative floating point value, where best value\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m0.85...\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    283\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m )\n\u001b[32m    289\u001b[39m output_errors = _average(\n\u001b[32m    290\u001b[39m     xp.abs(y_pred - y_true), weights=sample_weight, axis=\u001b[32m0\u001b[39m, xp=xp\n\u001b[32m    291\u001b[39m )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:116\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    114\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    115\u001b[39m y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m y_pred = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    118\u001b[39m     sample_weight = _check_sample_weight(sample_weight, y_true, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Алексей\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "print(\"Sklearn:\", evaluate_regression(y_test_reg, y_pred_sk_lin))\n",
    "print(\"Custom :\", evaluate_regression(y_test_reg, y_pred_my_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675b2bd",
   "metadata": {},
   "source": [
    "Кастомная реализация использует градиентный спуск, из-за особенностей моего датасета, где признаки имеют разные масштабы (например, Surface_Area — 515-809, а Overall_Height — 3,5–7), он не сходится, значения весов уходят в бесконечность, поэтому появляется NaN. На этапе улучшения мы масштабируем признаки и этой проблемы не будет!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46728643",
   "metadata": {},
   "source": [
    "Применим улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498511ee",
   "metadata": {},
   "source": [
    "Скейлинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce679561",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cls = StandardScaler()\n",
    "X_train_cls_scaled = scaler_cls.fit_transform(X_train_cls)\n",
    "X_test_cls_scaled = scaler_cls.transform(X_test_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84e381",
   "metadata": {},
   "source": [
    "Запуск улучшенной модели логической регрессии sklearn (классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64e9470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_log_opt = LogisticRegression(max_iter=1000, random_state=42)\n",
    "sk_log_opt.fit(X_train_cls_scaled, y_train_cls)\n",
    "y_pred_sk_opt = sk_log_opt.predict(X_test_cls_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25288476",
   "metadata": {},
   "source": [
    "Запуск кастомной улучшенной модели логической регрессии (классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d07ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_log_opt = MyLogisticClassifier(learning_rate=0.1, n_iterations=1000)\n",
    "my_log_opt.fit(X_train_cls_scaled, y_train_cls)\n",
    "y_pred_my_opt = my_log_opt.predict(X_test_cls_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03082b8",
   "metadata": {},
   "source": [
    "Вывод метрик классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "131787b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: {'Accuracy': 0.8097560975609757, 'F1': 0.807243989148881, 'ROC-AUC': 0.807142857142857}\n",
      "Custom : {'Accuracy': 0.8097560975609757, 'F1': 0.807243989148881, 'ROC-AUC': 0.807142857142857}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn:\", evaluate_classification(y_test_cls, y_pred_sk_opt))\n",
    "print(\"Custom :\", evaluate_classification(y_test_cls, y_pred_my_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f20c7",
   "metadata": {},
   "source": [
    "Скейлинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d112c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ced420",
   "metadata": {},
   "source": [
    "Генерация полиномиальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f34c5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_train_reg_poly = poly.fit_transform(X_train_reg_scaled)\n",
    "X_test_reg_poly = poly.transform(X_test_reg_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282a175",
   "metadata": {},
   "source": [
    "Скейлинг полиномиальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa1cdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_poly = StandardScaler()\n",
    "X_train_reg_poly_scaled = scaler_poly.fit_transform(X_train_reg_poly)\n",
    "X_test_reg_poly_scaled = scaler_poly.transform(X_test_reg_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa0e44",
   "metadata": {},
   "source": [
    "Запуск улучшенной модели линейной регрессии sklearn (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0fd8f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lin_poly = LinearRegression()\n",
    "sk_lin_poly.fit(X_train_reg_poly, y_train_reg)\n",
    "y_pred_sk_poly = sk_lin_poly.predict(X_test_reg_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dd47e",
   "metadata": {},
   "source": [
    "Запуск кастомной улучшенной модели линейной регрессии (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1fa1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lin_poly = MyLinearRegressor(learning_rate=0.1, n_iterations=3000)\n",
    "my_lin_poly.fit(X_train_reg_poly_scaled, y_train_reg)\n",
    "y_pred_my_poly = my_lin_poly.predict(X_test_reg_poly_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20735275",
   "metadata": {},
   "source": [
    "Вывод метрик регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c37203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: {'MAE': 0.60420014656585, 'RMSE': np.float64(0.8029563871333705), 'R2': 0.9938143588850876}\n",
      "Custom : {'MAE': 1.6080726898414572, 'RMSE': np.float64(2.2043898036311487), 'R2': 0.9533794286110633}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn:\", evaluate_regression(y_test_reg, y_pred_sk_poly))\n",
    "print(\"Custom :\", evaluate_regression(y_test_reg, y_pred_my_poly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
